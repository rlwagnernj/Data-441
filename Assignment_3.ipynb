{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import scipy.stats as stats \n",
    "from sklearn.model_selection import train_test_split as tts, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy.interpolate import interp1d, RegularGridInterpolator, griddata, LinearNDInterpolator, NearestNDInterpolator\n",
    "from math import ceil\n",
    "from scipy import linalg\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "\n",
    "cars_data = pd.read_csv('/Users/rebeccawagner/Documents/GitHub/Data 441/Data/cars.csv')\n",
    "concrete_data = pd.read_csv('/Users/rebeccawagner/Documents/GitHub/Data 441/Data/concrete.csv')\n",
    "housing_data = pd.read_csv('/Users/rebeccawagner/Documents/GitHub/Data 441/Data/housing.csv')\n",
    "\n",
    "cars_x = cars_data[['WGT','CYL','ENG']]\n",
    "cars_y = cars_data['MPG'].values\n",
    "\n",
    "concrete_x = concrete_data[['cement','slag','ash','water','superplastic','coarseagg','fineagg','age']]\n",
    "concrete_y = concrete_data['strength']\n",
    "\n",
    "housing_x = [['crime','residential','industrial','river','nox','rooms','older','distance','highway','tax','ptratio','lstat']]\n",
    "housing_y = housing_data[['cmedv']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the Gradient Boosting algorithm with user defined choices for Regressor_1 and Regressor_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(xtrain, ytrain, xtest, ytest, regressor_1, regressor_2):\n",
    "\n",
    "    mode1_1 = regressor_1\n",
    "    model_1.fit(xtrain,ytrain) # fit regressor 1 on the data\n",
    "    y_pred = model_1.predict(xtrain)\n",
    "    residuals = ytrain - y_pred # caclualte residuals of regressor 1\n",
    "    \n",
    "    model_2 = regressor_2.fit(xtrain,residuals) # fit regressor 2 on the data and residuals\n",
    "    y_pred = regressor_1.predict(xtrain) + regressor_2.predict(xtrain) \n",
    "    residuals = ytrain - y_pred\n",
    "\n",
    "    y_pred = regressor_1.predict(xtest) + regressor_2.predict(xtest)\n",
    "    return mse(y_pred, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = tts(cars_x, cars_y, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting(xtrain, ytrain, xtest, ytest, LR(), DTR())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Test the Boosted Locally Weighted Regressor with different choices of data (such as \"cars.csv\", \"concrete.csv\" and \"housing.csv\") and different choice of kernels, such as Gaussian, Tricubic, Epanechnikov and Quartic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Choices\n",
    "\n",
    "# Gaussian Kernel\n",
    "def Gaussian(x):\n",
    "  if len(x.shape)==1:\n",
    "    d = np.abs(x)\n",
    "  else:\n",
    "    d = np.sqrt(np.sum(x**2,axis=1))\n",
    "  return np.where(d>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*d**2))\n",
    "\n",
    "# Tricubic Kernel\n",
    "def Tricubic(x):\n",
    "  if len(x.shape) == 1:\n",
    "    x = x.reshape(-1,1)\n",
    "  d = np.sqrt(np.sum(x**2,axis=1))\n",
    "  return np.where(d>1,0,70/81*(1-d**3)**3)\n",
    "\n",
    "# Quartic Kernel\n",
    "def Quartic(x):\n",
    "  if len(x.shape) == 1:\n",
    "    x = x.reshape(-1,1)\n",
    "  d = np.sqrt(np.sum(x**2,axis=1))\n",
    "  return np.where(d>1,0,15/16*(1-d**2)**2)\n",
    "\n",
    "# Epanechnikov Kernel\n",
    "def Epanechnikov(x):\n",
    "  if len(x.shape) == 1:\n",
    "    x = x.reshape(-1,1)\n",
    "  d = np.sqrt(np.sum(x**2,axis=1))\n",
    "  return np.where(d>1,0,3/4*(1-d**2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that computes the Euclidean distance between all the observation in u and v\n",
    "def dist(u,v):\n",
    "  if len(v.shape)==1: # force v into column vector\n",
    "    v = v.reshape(1,-1)\n",
    "  d = np.array([np.sqrt(np.sum((u-v[i])**2,axis=1)) for i in range(len(v))]) # distance between all points in u and v\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of multidimensional LOWES\n",
    "\n",
    "def lw_ag_md(x, y, xnew,f=2/3,iter=3, intercept=True):\n",
    "\n",
    "  n = len(x)\n",
    "  r = int(ceil(f * n))\n",
    "  yest = np.zeros(n)\n",
    "\n",
    "  if len(y.shape)==1: # here we make column vectors\n",
    "    y = y.reshape(-1,1)\n",
    "\n",
    "  if len(x.shape)==1:\n",
    "    x = x.reshape(-1,1)\n",
    "  \n",
    "  if intercept:\n",
    "    x = np.column_stack([np.ones((len(x),1)),x])\n",
    "\n",
    "  h = [np.sort(np.sqrt(np.sum((x-x[i])**2,axis=1)))[r] for i in range(n)]\n",
    "  # dist(x,x) is always symmetric\n",
    "  w = np.clip(dist(x,x) / np.array(h), 0.0, 1.0)\n",
    "  w = (1 - w ** 3) ** 3\n",
    "\n",
    "  #Looping through all X-points\n",
    "  delta = np.ones(n)\n",
    "  for iteration in range(iter):\n",
    "    for i in range(n):\n",
    "      W = np.diag(delta).dot(np.diag(w[i,:]))\n",
    "      # when we multiply two diagonal matrices we get also a diagonal matrix\n",
    "      b = np.transpose(x1).dot(W).dot(y)\n",
    "      A = np.transpose(x1).dot(W).dot(x1)\n",
    "      ##\n",
    "      A = A + 0.0001*np.eye(x1.shape[1]) # if we want L2 regularization for solving the system\n",
    "      beta = linalg.solve(A, b)\n",
    "\n",
    "      #beta, res, rnk, s = linalg.lstsq(A, b)\n",
    "      yest[i] = np.dot(x1[i],beta.ravel())\n",
    "\n",
    "    residuals = y.ravel() - yest\n",
    "    s = np.median(np.abs(residuals))\n",
    "\n",
    "    delta = np.clip(residuals / (6.0 * s), -1, 1)\n",
    "\n",
    "    delta = (1 - delta ** 2) ** 2\n",
    "    \n",
    "  # here we are making predictions for xnew by using an interpolation and the predictions we made for the train data\n",
    "  if x.shape[1]==1:\n",
    "    f = interp1d(x.flatten(),yest,fill_value='extrapolate')\n",
    "    output = f(xnew)\n",
    "  else:\n",
    "    output = np.zeros(len(xnew))\n",
    "    for i in range(len(xnew)):\n",
    "      ind = np.argsort(np.sqrt(np.sum((x-xnew[i])**2,axis=1)))[:r]\n",
    "      pca = PCA(n_components=3)\n",
    "      x_pca = pca.fit_transform(x[ind])\n",
    "      tri = Delaunay(x_pca,qhull_options='QJ Pp')\n",
    "      f = LinearNDInterpolator(tri,yest[ind])\n",
    "      output[i] = f(pca.transform(xnew[i].reshape(1,-1))) \n",
    "      # the output may have NaN's where the data points from xnew are outside the convex hull of X\n",
    "\n",
    "  if sum(np.isnan(output))>0:\n",
    "    g = NearestNDInterpolator(x,yest.ravel()) \n",
    "    # output[np.isnan(output)] = g(X[np.isnan(output)])\n",
    "    output[np.isnan(output)] = g(xnew[np.isnan(output)])\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lowess_AG_MD:\n",
    "    def __init__(self, f = 1/10, iter = 3,intercept=True):\n",
    "        self.f = f\n",
    "        self.iter = iter\n",
    "        self.intercept = intercept\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        f = self.f\n",
    "        iter = self.iter\n",
    "        self.xtrain_ = x\n",
    "        self.yhat_ = y\n",
    "\n",
    "    def predict(self, x_new):\n",
    "        check_is_fitted(self)\n",
    "        x = self.xtrain_\n",
    "        y = self.yhat_\n",
    "        f = self.f\n",
    "        iter = self.iter\n",
    "        intercept = self.intercept\n",
    "        return lw_ag_md(x, y, x_new, f, iter, intercept) # this is actually our defined function of Lowess\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "    # suppose this estimator has parameters \"f\", \"iter\" and \"intercept\"\n",
    "        return {\"f\": self.f, \"iter\": self.iter,\"intercept\":self.intercept}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = tts(cars_x, cars_y, test_size = .3)\n",
    "\n",
    "gradient_boosting(xtrain, ytrain, xtest, ytest, Lowess_AG_MD(), DTR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Lowess_AG_MD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "490c0a39a4dd3df29f486b863cd658d9baeb3f977e83207532ec1f0044a62912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
